# 4 并行算法设计

### 并行算法的一般概念
并行计算
> 一组可同时执行并可相互协作的诸进程的集合

分类
  * 数值算法
    > 代数类数学运算
  * 非数值算法
    > 基于排序,选择,搜索,匹配等符号处理
  * 同步算法
    > 各进程执行需要相互等待
  * 异步算法
    > 个进程可以独立执行
  * 分布算法
  * 确定算法
  * 非确定算法
    > 随机算法,智能算法

##### 并行算法的表示
~~~language
par-do 语句
for i=1 to n par-do
  ...
end for
或
for i=1 to n do in parallel
  ...
end for

for all语句
for all Pi, where 0 <= i <= k do
  ...
end for
~~~

##### 并行算法的复杂性度量
成本c(n) = t(n) x p(n)
> t(n)为运行时间, p(n)为处理器数目,n为问题规模
* 成本最优性
  > 若c(n)等于在最坏情况下串行算法所需要的时间

加速比$S_p(n) = t_s(n) / t_p(n)$
> * $t_s(n)$为求解问题的最快的串行算法在最坏情形下运行时间,$t_p(n)$为求解同一问题的并行算法在最坏情形下的运行时间  
> * 反映了算法并行度对运行时间的改进程度  
> * 若$S_p(n) = p(n)$,为线性加速;若$S_p(n) > p(n)$为超线性加速

并行效率$E_p(n) = S_p(n) / p(n)$
> 反映了并行系统中处理器的利用程度

工作量W(n)
> 并行算法所执行的操作步数(与处理器数目无关)
### 并行计算模型
对并行计算机的抽象,为设计,分析和评价算法提供基础
##### SISD,MIMD
##### SIMD-DM模型
具体在
[2](./2.md)
##### PRAM模型(SIMD-SM模型)
![PRAM](./pic/PRAM.png)
* 有一个集中的共享存储器和一个指令控制器,通过共享存储(SM)的R/W交换数据,隐式同步计算
* 在一个时钟周期内,每个处理器执行一条指令,可完成3个操作
  * 从存储器取出数据
  * 完成一个运算
  * 将结果存会存储器
* 存取模式
  > $T_{EREW} >= T_{CREW} >= T_{CRCW}\\T_{EREW} = O(T_{CREW}\centerdot log(p)) = O(T_{CRCW}\centerdot log(p))$
  * CRCW:并发读并发写,冲突解决模式
    * 相同/公共并发读写
      > 仅允许写入相同数据
    * 优先并发读
      > 仅允许优先级最高的处理器写入
    * 任意并发读写
      > 允许任意处理器自由写入
  * CREW:并发读互斥写
  * EREW:互斥读,互斥写
* 特点
  * 全局共享存储,单一地址空间
  * 同步,通信和并行化的开销为零
* 优点
  * 适合并行算法和复杂性分析,易于使用
  * 隐藏并行机的通讯,同步等细节
  * 易于扩展:可以根据需要,可以在PRAM模型中加入一些诸如同步和通信等需要考虑的内容
* 缺点
  * 不适合MIMD并行机
  * 忽略竞争,通讯延迟的因素
  * 由于使用一个全局共享存储器,不适合分布存储结构的并行机
  * 模型是同步的,不能反映现实中很多系统的异步性
  * 假设了每个处理器可在单位时间访问共享存储器的任一单元,因此要求处理机间通信无延迟,无线带宽和无开销,不现实

* 其他PRAM
  * 分相PRAM(Phased PRAM)
    * 异步PRAM模型
    * 各个处理器异步执行局部程序,每个局部程序的最后一条语句是同步障指令
  * 本地存储PRAM(LPRAM: Local memory PRAM)
    * 考虑本地存储和远程存储的开销不同
  * 块PRAM(BPRAM:Block PRAM)
    * LPRAM+通信开销
##### BSP模型(MIMD-DM模型)
![BSP](./pic/BSP.png)
块同步模型
* 一种异步MIMD-DM(分布式存储)模型,支持消息传递,块内异步并行,块间显式同步
* 组成部分:
  * 节点:处理器,本地存储
  * 通信网络:点到点,消息传递
  * 同步障:同步机制

超步
![superstep](./pic/superstep.png)
> BSP计算过程由若干超级步组成

模型参数
* 参数w:计算参数
  * 每个超步内最大的计算时间
  * 计算操作最多为w个时钟周期
* 参数g:带宽参数
  * 单位消息所的通信时钟数-网络带宽的倒数
  * 关系因子h:每个节点至多发送和接受h个信息
  * 通信操作最多gh个时钟周期
* 参数l:同步障参数
  * 同步障操作最多l个周期

时间复杂度
* Valiant公式: max{w,gh,l}
* McColl公式: w+gh+l

优点:
* 软硬件之间架起一座类似冯诺依曼机的桥梁(桥模型)
* 将处理器和路由器分开,强调了计算任务和通信任务的分开,而路由器仅仅万恒点到点的消息传递,不提供组合,复制和广播等功能.这掩盖具体的互连网络拓扑和通信协议

缺点:
* 需要显示同步,编程效率不高
* 全局障同步假定是用特殊硬件的支持的,但在很多并行机中可能没有相应的硬件
##### LogP模型(基于MPC)
一种分布存储,点到点通信多处理机模型,其中通讯由一组参数描述,实行隐式同步

模型参数:
* L:网络时延
* o: 通信开销
* g: gap=1/bandwidth
* P:处理器数目

模型的使用

![mxsy](./pic/mxsy.png)
* 从处理器发送n个消息到处理器,需要时间:2o+L+g(n-1)

优点:
* 异步模型,没有同步障
* 捕捉了并行计算机的通讯瓶颈
* 通信有一组参数描述,但并不涉及具体网络结构,隐藏了并行机的网络拓扑,路由,协议
* 可以应用到共享存储,消息传递,数据并行的模型中

缺点:
* 难以算法描述,设计和分析
* 对网络通信模式描述如不够深入
* 主要适用于消息传递算法设计,对于共享存储模式,则简单认为远地读操作相当于两次消息传递,未考虑流水线预取技术,Cache引起的数据一致以及Cache命中率对计算影响

### 三种模型比较
![mxbj5.1](./pic/mxbj5.1.png)
### 并行算法的一般设计方法
##### 串行算法的直接并行化
方法描述
> 发掘和利用现有串行算法中的并行性,直接将串行算法改造

评注:
* 有串行算法直接并行化的方法是并行算法设计的最常用方法之一
* 不是所有的串行算法都可以直接并行化
* 一个好的串行算法并不能并行化为一个好的并行算法
* 许多数值串行算法可以并行化为有效数据并行算法
##### 从问题描述开始设计并行算法
方法描述
> 从问题本身描述触发,不考虑相应的串行算法,设计一个全新的并行算法

评注:
* 挖掘问题的固有特性与并行的关系
* 设计全新的并行算法是一个挑战性和创造性的工作
##### 借用已有算法求解新问题
方法描述
> 找出求解问题和某个已解决问题之间的联系,改造或利用已知算法引用到求解问题上
评注:
* 创造性工作

##### 并行算法设计技术
平衡树方法
> 树叶结点为输入,中间结点为处理结点,由叶向根或由根向叶逐层并行处理

倍增技术(指针跳跃技术)
> 适合于处理链表或有向树之类  
> 当递归调用时,苏姚处理数据之间的距离逐步加倍,经过k步后即可完成距离为$2^k$的所有数据的计算

分治策略
> 将原问题划分为若干个相同的子问题分而治之,若子问题仍然较大,则可以反复递归应用分治策略处理这些子问题,直至子问题易求解
* 步骤
  1. 将输入划分成若干个规模相等的子问题
  2. 同时(并行地)递归求解这些子问题
  3. 并行地归并子问题的解成为原问题的解

划分原理
> 将原问题划分成p个独立的规模几乎相等的子问题  
> p台处理器并行地求解各子问题
* 重点
> 子问题易解,组合成原问题方便

* 划分方法
  * 均匀划分
  * 方根划分
  * 对数划分
  * 对数划分
  * 功能划分

流水线技术
> 将算法流程划分成p个前后衔接的任务片段,每个任务片段的输出作为下一个任务片段输入  
> 所有任务片段按仙童的速率产生结果
##### 并行算法的一般设计过程
四个阶段
* 划分(Partitioning)
  > 分解成较小的任务,开拓并发性
  * 数据集和计算集互不相交
  * 划分阶段忽略处理器数目和目标机器的体系结构
  * 划分
    1. 域分解/数据分解
    > 划分的对象是数据,可以是算法的输入数据,中间处理数据和输出数据
      * 将数据分解成大致相等的小数据片
      * 划分时考虑数据上的相应操作
      * 如果需要别的任务中的数据,则会产生任务间的通信
    2. 功能分解
    > 划分的对象是计算,将计算划分为不同的任务
      * 划分后,研究不同任务所需的数据
        > 如果数据不想交,则划分成功;如果数据有重叠,则需要重新进行域分解和功能分解
  * 划分依据
    * 灵活性
    * 是否避免冗余
    * 划分的任务尺寸
    * 任务数和问题尺寸比例
    * 功能分解是否合理
* 通信
  > 确定诸任务间的数据交换,监测划分的合理性
  * 局部/全局通信
    > 局部通信:限制在一个邻域内  
    > 全局通信:许多任务参与,非局部的
  * 结构化/非结构化通信
    > 结构化通信:每个任务的通信模式是相同  
    > 非结构化通信:没有一个统一的通信模式
  * 静态/动态通信
    > 动态通信:通信模式不规整
  * 同步/异步通信
    > 同步通信:通信双方同时产生通信操作  
    > 异步通信: 应答式
  * 通信依据
    * 所有任务是否执行大致相当的通信
    * 是否尽可能局部通信
    * 通信操作是否能并行执行
    * 同步任务的计算是否并行执行
* 组合
  > 依据任务的局部性,组合成更大的任务
  * 由抽象到具体的过程,使得组合的任务能在一类并行机上有效执行
  * 合并小尺寸任务,减少任务数
    > 如果任务数= 处理器数,则完成了映射过程
  * 通过增加任务的粒度和重复计算
    > 减少通信成本
  * 保持映射和扩展的灵活性
    > 降低软件工程成本
    * 表面-容积效应
      * 通信量与任务子集的表面正比
      * 计算量与任务子集的体积成正比
    * 重复计算
      * 减少通信量,但增加了计算量
      * 应减少算法的总运算时间
* 映射
  > 映射到具体处理器,减少算法执行和似箭
  * 策略
    * 任务在不同处理器并发执行
      > 并发性
    * 通信频繁任务放在同一个处理器上
      > 局部性
  * 负载平衡算法
    * 事先确定
    * 随机确定
    * 动态负载
    * 基于域分解
      * 递归对剖
      * 局部算法
      * 概率算法
      * 循环映射
  * 任务调度算法
    * 经理/雇员模式
    * 非集中式模式
      > 分布式调度

